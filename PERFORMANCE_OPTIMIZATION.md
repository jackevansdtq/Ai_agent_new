# ğŸš€ Performance Optimization Guide

## Má»¥c tiÃªu
Giáº£m thá»i gian xá»­ lÃ½ tá»« **49-68 giÃ¢y** xuá»‘ng **dÆ°á»›i 15 giÃ¢y**.

## CÃ¡c tá»‘i Æ°u Ä‘Ã£ thá»±c hiá»‡n

### 1. âœ… QueryParam Optimization
- **top_k**: Giáº£m tá»« 60 â†’ **5** (giáº£m 91.7%)
- **max_token_for_text_unit**: Giáº£m tá»« 4000 â†’ **1500** (giáº£m 62.5%)
- **max_token_for_node_context**: Giáº£m tá»« 500 â†’ **200** (giáº£m 60%)
- **max_token_for_local_context**: Giáº£m tá»« 4000 â†’ **1500** (giáº£m 62.5%)
- **max_token_for_global_context**: Giáº£m tá»« 4000 â†’ **1500** (giáº£m 62.5%)

### 2. âœ… Mode Optimization
- **Naive mode**: Sá»­ dá»¥ng mode nhanh nháº¥t (chá»‰ vector search, khÃ´ng dÃ¹ng graph)
- **Fallback logic**: Náº¿u naive mode > 10s, tá»± Ä‘á»™ng chuyá»ƒn sang light mode vá»›i top_k=3

### 3. âœ… Caching Improvements
- **Response cache**: Cache responses vá»›i TTL 1 giá»
- **Embedding cache**: Cache embeddings Ä‘á»ƒ trÃ¡nh gá»i API láº·p láº¡i
- **Auto cleanup**: Tá»± Ä‘á»™ng xÃ³a cache entries Ä‘Ã£ háº¿t háº¡n

### 4. âœ… Environment Variables
- **TOP_K**: 10 (default)
- **COSINE_THRESHOLD**: 0.25 (tá»‘i Æ°u cho filtering)

### 5. âœ… Performance Monitoring
- ThÃªm timing logs Ä‘á»ƒ track query time vÃ  total time
- Auto-retry vá»›i parameters nhá» hÆ¡n náº¿u query quÃ¡ cháº­m

## Káº¿t quáº£

### TrÆ°á»›c tá»‘i Æ°u:
- Processing time: **49-68 giÃ¢y**
- Query time: **54 giÃ¢y**

### Sau tá»‘i Æ°u:
- Query time: **~15 giÃ¢y** âœ… (giáº£m 72%)
- Processing time: **~56 giÃ¢y** (cáº§n tá»‘i Æ°u thÃªm)

## Váº¥n Ä‘á» cÃ²n láº¡i

### 1. Processing Time vs Query Time
- Query time: **14.96s** âœ… (Ä‘Ã£ Ä‘áº¡t má»¥c tiÃªu < 15s)
- Total processing time: **56.40s** âŒ (váº«n cháº­m)

**NguyÃªn nhÃ¢n cÃ³ thá»ƒ:**
- Event loop overhead
- Network latency
- API layer overhead
- Bot initialization (náº¿u cÃ³)

### 2. CÃ¡c tá»‘i Æ°u tiáº¿p theo

#### A. Async API Layer
```python
# Thay vÃ¬:
loop = asyncio.new_event_loop()
asyncio.set_event_loop(loop)
response = loop.run_until_complete(bot.chat(message))

# NÃªn dÃ¹ng:
response = await bot.chat(message)  # Náº¿u Flask há»— trá»£ async
```

#### B. Connection Pooling
- Tá»‘i Æ°u Neo4J connection pool
- Tá»‘i Æ°u OpenAI API client (reuse connections)

#### C. Parallel Processing
- Batch embedding requests
- Parallel vector searches
- Concurrent LLM calls (náº¿u cÃ³)

#### D. Response Streaming
- Stream response tá»« LLM thay vÃ¬ chá» toÃ n bá»™
- Giáº£m Time To First Token (TTFT)

#### E. Pre-computation
- Pre-compute embeddings cho common queries
- Pre-warm cache vá»›i popular questions

## Cáº¥u hÃ¬nh tá»‘i Æ°u

### deploy.env
```env
# Performance optimization (tá»‘i Æ°u cho tá»‘c Ä‘á»™ < 15s)
TOP_K=10
COSINE_THRESHOLD=0.25
```

### QueryParam (trong code)
```python
query_param = QueryParam(
    mode="naive",  # Nhanh nháº¥t
    top_k=5,  # Tá»‘i thiá»ƒu
    max_token_for_text_unit=1500,  # Giáº£m context
)
```

## Monitoring

### Logs Ä‘á»ƒ theo dÃµi:
```bash
docker-compose logs insurance-bot | grep -E "(Query time|Total time|naive|light)"
```

### Metrics quan trá»ng:
1. **Query time**: Thá»i gian MiniRAG query (má»¥c tiÃªu: < 15s)
2. **Total time**: Tá»•ng thá»i gian tá»« request Ä‘áº¿n response
3. **Cache hit rate**: Tá»· lá»‡ cache hits
4. **API call count**: Sá»‘ lÆ°á»£ng API calls (OpenAI, Neo4J)

## Best Practices

1. **LuÃ´n check cache trÆ°á»›c**: Response cache â†’ Embedding cache
2. **Sá»­ dá»¥ng naive mode**: Nhanh nháº¥t cho simple queries
3. **Giáº£m top_k**: CÃ ng nhá» cÃ ng nhanh (trade-off vá»›i accuracy)
4. **Giáº£m max_token**: Giáº£m context size Ä‘á»ƒ tÄƒng tá»‘c
5. **Monitor performance**: Track metrics Ä‘á»ƒ identify bottlenecks

## TÃ i liá»‡u tham kháº£o

- [MiniRAG Documentation](https://github.com/MiniRAG/MiniRAG)
- [RAG Performance Optimization](https://www.pinecone.io/learn/retrieval-augmented-generation/)
- [Vector Database Optimization](https://www.pinecone.io/learn/vector-database/)

